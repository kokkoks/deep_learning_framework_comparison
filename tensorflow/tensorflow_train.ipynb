{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ffeba22-068c-4ef5-9da7-b17df38d9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Helper libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Custom libraries\n",
    "from tensorflow_generator import TensorflowDataGenerator, TensorflowDataGenerator_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6df31839-a3a4-429f-9274-715c84d6c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Set the CNN parameters\n",
    "num_epoch = 5\n",
    "batch_size = 6\n",
    "framework = \"tensorflow\"\n",
    "train_type = \"manual\"\n",
    "im_size = 224\n",
    "num_im = 1000\n",
    "predict = True\n",
    "model_type=\"simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "554ca9cd-a0ac-4b3b-82c4-810f9cbb6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up directories\n",
    "root_path = \"../\"\n",
    "data_dir = os.path.join(root_path, \"dogs-vs-cats/train\")\n",
    "log_dir = os.path.join(\n",
    "    root_path,\n",
    "    \"logs\",\n",
    "    framework,\n",
    "    model_type,\n",
    "    \"logs\",\n",
    "    train_type + \"_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "if predict:\n",
    "    ckpt_name = f\"{train_type}_20200816-184346\"\n",
    "    ckpt_dir = os.path.join(\n",
    "        root_path, \"logs\", framework, model_type, \"ckpts\", ckpt_name\n",
    "    )\n",
    "else:\n",
    "    ckpt_dir = os.path.join(\n",
    "        root_path,\n",
    "        \"logs\",\n",
    "        framework,\n",
    "        model_type,\n",
    "        \"ckpts\",\n",
    "        train_type + \"_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74871191-aaf2-4b7f-9acd-c9d1743f12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup input pipeline\n",
    "train_dir = os.path.join(root_path, \"dogs-vs-cats/train\")\n",
    "test_dir = os.path.join(root_path, \"dogs-vs-cats/test\")\n",
    "\n",
    "train_gen = TensorflowDataGenerator(\n",
    "    train_dir, batch_size, im_size=im_size, num_im=num_im, shuffle=True\n",
    ")\n",
    "val_imgs = train_gen.load_val()\n",
    "test_gen = TensorflowDataGenerator_Test(test_dir, batch_size, im_size=im_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fb1ed58-6caa-4655-b43c-2b2eea3997e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,086,913\n",
      "Trainable params: 13,086,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up model option 1\n",
    "model = Sequential(\n",
    "    [\n",
    "        layers.Conv2D(\n",
    "            32,\n",
    "            3,\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            input_shape=(im_size, im_size, 3),\n",
    "        ),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff2a8c6d-5f2c-4c1d-8ecc-6fceb90afeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model option 1.2\n",
    "model = Sequential()\n",
    "model.add(layers.Conv2D(\n",
    "        32,\n",
    "        3,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        input_shape=(im_size, im_size, 3)\n",
    "    ))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation=\"relu\"))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f25267e8-c8b1-49ca-abf9-1a6492f40247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model option 2\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(im_size, im_size, 3),)\n",
    "x = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")(input_layer)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation=\"relu\")(x)\n",
    "output_layer = layers.Dense(1)(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fb1dd29-4a25-461e-af49-aa1a946fa747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 112, 112, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 56, 56, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 28, 28, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 13,086,913\n",
      "Trainable params: 13,086,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7c26bcb-0673-4ec4-8b49-522dc6fff7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model option 3\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "class CustomModel(Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.conv1 = layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\")\n",
    "        self.pool = layers.MaxPooling2D()\n",
    "        self.conv2 = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")\n",
    "        self.conv3 = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")\n",
    "        self.conv4 = layers.Conv2D(128, 3, padding=\"same\", activation=\"relu\")\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.fc1 = layers.Dense(512, activation=\"relu\")\n",
    "        self.fc2 = layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bd7adf5-134b-4ffc-93e0-76159f033d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Get model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80485a09-5d62-4596-a3c2-3d135a40ba29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_huber_loss(y_true, y_pred):\n",
    "    threshold = 1\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) <= threshold\n",
    "    small_error_loss = tf.square(error) / 2\n",
    "    big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))\n",
    "    return tf.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9206b9e6-de59-48d5-afee-864d4822ec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kokubuntu/.pyenv/versions/3.9.10/lib/python3.9/site-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.0005148930940777063 \tValidation Loss: 0.00018744784756563604 \tTraining Accuracy: 1.0 \tValidation Accuracy: 1.0 \tTime taken: 4.099570872000186\n",
      "Epoch: 2 \tTraining Loss: 0.0002657287986949086 \tValidation Loss: 0.00011425477714510635 \tTraining Accuracy: 1.0 \tValidation Accuracy: 1.0 \tTime taken: 3.531686952999735\n",
      "Epoch: 3 \tTraining Loss: 0.0003042563912458718 \tValidation Loss: 0.00010934464808087796 \tTraining Accuracy: 1.0 \tValidation Accuracy: 1.0 \tTime taken: 3.5307279200005723\n",
      "Epoch: 4 \tTraining Loss: 0.00028295995434746146 \tValidation Loss: 3.576412927941419e-05 \tTraining Accuracy: 1.0 \tValidation Accuracy: 1.0 \tTime taken: 3.780366449000212\n",
      "Epoch: 5 \tTraining Loss: 0.0004524594114627689 \tValidation Loss: 0.00036074992385692894 \tTraining Accuracy: 1.0 \tValidation Accuracy: 1.0 \tTime taken: 3.6673804660003952\n"
     ]
    }
   ],
   "source": [
    "if train_type == \"auto\":\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "    # Setup callbacks\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=ckpt_dir,\n",
    "        save_weights_only=True,\n",
    "        monitor=\"val_acc\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "\n",
    "    model.compile(loss=my_huber_loss, optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    # train the model\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_imgs,\n",
    "        validation_steps=len(val_imgs[0]) // batch_size,\n",
    "        epochs=num_epoch,\n",
    "        callbacks=[tensorboard_callback, model_checkpoint_callback],\n",
    "        use_multiprocessing=True,\n",
    "        workers=8,\n",
    "    )\n",
    "\n",
    "elif train_type == \"manual\":\n",
    "    # loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    loss_fn = my_huber_loss\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "    train_acc = tf.keras.metrics.Mean()\n",
    "    train_loss = tf.keras.metrics.Mean()\n",
    "    val_acc = tf.keras.metrics.Mean()\n",
    "    val_loss = tf.keras.metrics.Mean()\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x, training=True)\n",
    "            loss_value = loss_fn(y, logits)\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "        acc_value = tf.math.equal(\n",
    "            y, tf.math.round(tf.keras.activations.sigmoid(logits))\n",
    "        )\n",
    "        train_acc.update_state(acc_value)\n",
    "        train_loss.update_state(loss_value)\n",
    "\n",
    "    @tf.function\n",
    "    def test_step(x, y):\n",
    "        val_logits = model(x, training=False)\n",
    "        loss_value = loss_fn(y, val_logits)\n",
    "        acc_value = tf.math.equal(\n",
    "            y, tf.math.round(tf.keras.activations.sigmoid(val_logits))\n",
    "        )\n",
    "        val_acc.update_state(acc_value)\n",
    "        val_loss.update_state(loss_value)\n",
    "        return loss_value, acc_value\n",
    "\n",
    "    # Setup tensorboard\n",
    "    file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "    best_val_acc = 0  # for model check pointing\n",
    "    # Epoch loop\n",
    "    for epoch in range(1, num_epoch + 1):\n",
    "        start_time = timer()\n",
    "        # Training loop\n",
    "        for inputs, targets in train_gen:\n",
    "            train_step(inputs, targets)\n",
    "\n",
    "        # Validation loop\n",
    "        for batch_idx in range(0, len(val_imgs[1]), batch_size):\n",
    "            inputs = val_imgs[0][batch_idx : batch_idx + batch_size, ...]\n",
    "            targets = val_imgs[1][batch_idx : batch_idx + batch_size]\n",
    "            test_step(inputs, targets)\n",
    "\n",
    "        # Log metrics to tensorboard\n",
    "        end_time = timer()\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar(\"Loss/train\", train_loss.result(), step=epoch)\n",
    "            tf.summary.scalar(\"Loss/validation\", val_loss.result(), step=epoch)\n",
    "            tf.summary.scalar(\"Accuracy/train\", train_acc.result(), step=epoch)\n",
    "            tf.summary.scalar(\"Accuracy/validation\", val_acc.result(), step=epoch)\n",
    "            tf.summary.scalar(\"epoch_time\", end_time - start_time, step=epoch)\n",
    "\n",
    "        # Display metrics at the end of each epoch.\n",
    "        print(\n",
    "            f\"Epoch: {epoch} \\tTraining Loss: {train_loss.result()} \\tValidation Loss: {val_loss.result()} \\tTraining Accuracy: {train_acc.result()} \\tValidation Accuracy: {val_acc.result()} \\tTime taken: {end_time - start_time}\"\n",
    "        )\n",
    "\n",
    "        # checkpoint if improved\n",
    "        if val_acc.result() > best_val_acc:\n",
    "            model.save_weights(ckpt_dir)\n",
    "            best_val_acc = val_acc.result()\n",
    "\n",
    "        # Reset training metrics at the end of each epoch\n",
    "        train_acc.reset_states()\n",
    "        train_loss.reset_states()\n",
    "        val_acc.reset_states()\n",
    "        val_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575111a-cf78-4df8-88b3-cdbd4e1aaf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(ckpt_dir)\n",
    "for inputs in test_gen:\n",
    "    outputs = model(inputs, training=False)\n",
    "    break\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7142dd5d-081e-40d8-be4b-c49dcb428624",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
